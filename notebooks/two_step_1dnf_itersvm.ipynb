{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e9d2ff",
   "metadata": {},
   "source": [
    "# Two-Step Techniques (1-DNF & iterable SVM)\n",
    "\n",
    "This method learns $P(y|x)$ by a two-step technique (step1: 1-DNF, step2: iterable SVM, step3: F1')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe001d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3fd914",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the SCAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_scar, load_sar, load_pg\n",
    "\n",
    "train, valid, test, c = load_scar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee8e76",
   "metadata": {},
   "source": [
    "### Step1: 1-DNF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3f8d8",
   "metadata": {},
   "source": [
    "#### Find strong positive features based on the bias of the labeled data.\n",
    "In this section, we consider the strong positive feature for each axis direction. Specifically, for i-th axis direction, let \"$x_i > B_i$\" be the strong positive feature, that $B_i$ satisfies the following two points;\n",
    "1. 99% of the labeled data $x$ has the feature \"$x_i > B_i$\".\n",
    "2. Of the $B_i$ s that satisfy 1, we choose the one with the largest $r$, where $r$ is the product of each ratio of the labeled and unlabeled data that satisfies \"$x_i > B_i$\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab30d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs, train_ys, train_ss, train_es = train\n",
    "\n",
    "# Strong Positive Feature (SPF)\n",
    "# SPF[i] is the threshold B_i\n",
    "SPF = [None] * train_xs.shape[-1]\n",
    "\n",
    "N_unlabeled = len(train_ss[train_ss == 0])\n",
    "N_labeled = len(train_ss[train_ss == 1])\n",
    "\n",
    "for axis in range(train_xs.shape[-1]):\n",
    "    train_xs_ = list(zip(train_xs[:, axis], train_ss))\n",
    "    train_xs_ = sorted(train_xs_)\n",
    "    \n",
    "    n_labeled, n_unlabeled = N_labeled, N_unlabeled\n",
    "    r = (n_labeled / N_labeled) * (1 - n_unlabeled / N_unlabeled)\n",
    "    B = train_xs_[0][0]\n",
    "    px = - float('inf')\n",
    "    for x, s in train_xs_:\n",
    "        if s == 0:\n",
    "            n_unlabeled -= 1\n",
    "        elif s == 1:\n",
    "            r_ = (n_labeled / N_labeled) * (1 - n_unlabeled / N_unlabeled)\n",
    "            if x != px and n_labeled / N_labeled >= 0.99 and r < r_:\n",
    "                r = r_\n",
    "                B = x\n",
    "            n_labeled -= 1\n",
    "        px = x\n",
    "    SPF[axis] = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SPF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc820e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the labeled data be positive, and the unlabeled data that does not satisfy any of the strong positive features be negative.\n",
    "# The data neither positive nor negative is unlabeled.\n",
    "# y_: the label (pos: 1, neg: 0, unlabeled: -1)\n",
    "new_train_ys = np.array([0]*(len(train_xs)))\n",
    "for i in range(len(train_xs)):\n",
    "    if train_ss[i] == 1:\n",
    "        new_train_ys[i] = 1\n",
    "    elif all([train_xs[i][j] < SPF[j] for j in range(train_xs.shape[-1])]):\n",
    "        new_train_ys[i] = 0\n",
    "    else:\n",
    "        new_train_ys[i] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20b04b",
   "metadata": {},
   "source": [
    "### Visualize the newly created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_x_y, plot_x_s, plot_x_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x_s(train_xs, train_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb605df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x_y(train_xs[new_train_ys!=-1], new_train_ys[new_train_ys!=-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76672ec5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step2: Apply iterable SVM for the semi-supervised dataset\n",
    "Now, we have positive-labeled data, negative-labeled data, and unlabeled data.\n",
    "We iterate the following steps until the classifier (SVM) is converged.\n",
    "1. We learn an SVM classifier only using positive-labeled data and negative-labeled data.\n",
    "2. We give a negative label to the unlabeled data determined to be negative by the SVM.\n",
    "3. If no data is given a label in step2, the SVM is converged. If not, go back to step1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd807bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clfs = []\n",
    "new_train_ys_ = new_train_ys.copy()\n",
    "converged = False\n",
    "while not converged:\n",
    "    clf= SVC(kernel='linear', random_state=42)\n",
    "    clf.fit(train_xs[new_train_ys_!=-1], new_train_ys_[new_train_ys_!=-1])\n",
    "    new_train_ys_hat = clf.predict(train_xs)\n",
    "    clfs.append(clf)\n",
    "    if len(new_train_ys_[(new_train_ys_ == -1) & (new_train_ys_hat == 0)]) == 0:\n",
    "        converged = True\n",
    "    else:\n",
    "        new_train_ys_[(new_train_ys_ == -1) & (new_train_ys_hat == 0)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6923b4",
   "metadata": {},
   "source": [
    "The upper figure shows the classification results by SVM obtained at the first iteration, and the lower figure shows the classification results by SVM obtained at convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a339294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_x_y_list(train_xs, [clfs[i].predict(train_xs) for i in [0, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666540b",
   "metadata": {},
   "source": [
    "### Step3: Choose the best classfier in terms of F1'\n",
    "The SVM obtained at convergence is not necessarily the best. Therefore, we evaluate each of the SVMs obtained by the iterations with F1' and choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import f1_prime\n",
    "f1_primes = [f1_prime(train_ss, clfs[i].predict(train_xs)) for i in range(len(clfs))]\n",
    "optim_clf_idx = f1_primes.index(max(f1_primes))\n",
    "plot_x_y(train_xs, clfs[optim_clf_idx].predict(train_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956968be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs, test_ys, test_ss, test_es = test\n",
    "\n",
    "test_ys_hat = clfs[optim_clf_idx].predict(test_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f9e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x_y(train_xs, clfs[optim_clf_idx].predict(train_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d694c5b",
   "metadata": {},
   "source": [
    "### Evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "for i in range(len(clfs)):\n",
    "    if i == optim_clf_idx:\n",
    "        print(\"f1' for train: {:.3f}\\tf1 for test: {:.3f}\\tbest f1' for train\".format(f1_primes[i], f1_score(test_ys, clfs[i].predict(test_xs))))\n",
    "    else:\n",
    "        print(\"f1' for train: {:.3f}\\tf1 for test: {:.3f}\".format(f1_primes[i], f1_score(test_ys, clfs[i].predict(test_xs))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28975797",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca723481",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x_y(test_xs, test_ys_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
